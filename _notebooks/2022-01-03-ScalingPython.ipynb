{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Scaling your python powered ML pipeline\"\n",
    "> \"What does it mean to scale?\"\n",
    "\n",
    "- toc: false \n",
    "- badges: false \n",
    "- comments: true\n",
    "- categories: [python, data-science]\n",
    "- image: images/scalingpython.png\n",
    "- permalink: /PandasSQL/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scaling, in general, is starting out with a small solution and growing it into a bigger solution.\n",
    "\n",
    "![banner](my_icons/scalingpython.png)\n",
    "\n",
    "Different people mean different things when they talk about scaling. Do you want to scale a mountain, a web app, or an ML pipeline?\n",
    "\n",
    "Even when talking about machine learning, scaling can mean different things:~\n",
    "    \n",
    "    \n",
    "- Processing more data\n",
    "- Using a more complex model\n",
    "- Running more often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling comes at a cost\n",
    "\n",
    "Scaling requires resources and cost to execute. The cost can be in the form of:~\n",
    "\n",
    "- Developer time required for code refactoring and optimization for performance\n",
    "- Performance optimized hardware for accelerated computing\n",
    "- Distributed processing requires more computers\n",
    "- Longer wait time for processing more on the same infrastructure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think before you scale\n",
    "\n",
    "There are two important things to consider before you invest in scaling:~\n",
    "\n",
    "- **What are your goals?** You must decide beforehand, what is good enough? Over-engineering is a trap, all engineers are familiar with. Don't over-engineer!\n",
    "\n",
    "- **Measure your code?** To treat a patient, a doctor has to determine what the illness is? Likewise, you need to measure your code for bottlenecks before deciding on a scaling strategy.\n",
    "There are many tools that can use to profile your python code. [Scalene](https://github.com/plasma-umass/scalene) is one of the most complete measuring tools available at the moment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to scale?\n",
    "\n",
    "1. **Increase code efficiency:** Python is designed for ease of use and easy extension, but not performance. As a developer, the onus is on you to do more work so that the application executes less code. Whenever possible use vectorized library functions instead of loops.\n",
    "Python is successful in data science because of the pre-compiled code offered by data-appropriate libraries in the pydata stack such as [pandas](https://pandas.pydata.org/) and [numpy](https://numpy.org/).\n",
    "\n",
    "2. **Adding parallelism:** You can achieve parallelism on a single machine or by using multiple machines. In principle, you want to stay on a single machine as much as possible as distributed computing increased complexity because of the following challenges:\n",
    "    - network transfer\n",
    "    - task management\n",
    "    - cluster management\n",
    "\n",
    "    2.1 **Hardware accelerators:** You can leverage GPUs and \n",
    "    TPUs for your ML workflows. Libraries such as CuPy and \n",
    "    RAPIDS leverage GPUs. There are non-GPU accelerators also \n",
    "    like [TPUs offered by Google](https://cloud.google.com/tpu/docs/tpus) and [Apple Neural Engine](https://developer.apple.com/machine-learning/core-ml/).\n",
    "\n",
    "    2.2 **Distributed Computing:** Going distributed is much \n",
    "    harder for the aforementioned reasons but if you have to \n",
    "    then you can look at the following projects:\n",
    "    - [Dask](https://dask.org/): Distributed data frames, machine learning and more\n",
    "    - [Ray](https://www.ray.io/ray-core): Parallel python framework\n",
    "    - [Horovod](https://eng.uber.com/horovod/): Uber's framework for distributed deep learning\n",
    "    - [PySpark](https://spark.apache.org/docs/latest/api/python/index.html): Python wrapper for Apache Spark ecosystem\n",
    "\n",
    "Whichever direction you take on your scaling journey, be sure to pause before you commit, and solve one problem at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: I have not covered I/O scaling in this post. That is a conversation for some other day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.buymeacoffee.com/alephthoughts\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" alt=\"Buy Me A Coffee\" style=\"height: 60px !important;width: 217px !important;\" ></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
